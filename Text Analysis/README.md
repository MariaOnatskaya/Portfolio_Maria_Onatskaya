# Toxic Comment Detection Tool Development  

## Description:  
Developed a model for classifying user comments as positive or toxic, with the goal of sending toxic comments for moderation. The task involved training the model on a labeled dataset to achieve an F1-score of at least 0.75.  

## Key Achievements:  
- Performed text preprocessing: lemmatization (WordNetLemmatizer), tokenization (word_tokenize), and removal of stopwords.  
- Vectorized text data using TF-IDF.  
- Created a word cloud visualization.  
- Trained three classification models: LogisticRegression, LGBMClassifier, and DecisionTreeClassifier.  
- Evaluated model performance, with LGBMClassifier achieving the best results.  

## Tools:  
Python, Pandas, NumPy, NLTK (WordNetLemmatizer, word_tokenize), Scikit-learn, LightGBM, TF-IDF, Matplotlib, Seaborn.
